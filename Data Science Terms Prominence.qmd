---
title: "Prominence of occurrence accorded to data science and other related terms in Philippine newspapers"
date: last-modified
author:
  - name: Dan Anthony Dorado
    orcid: 0000-0002-2844-0732
    email: dddorado@up.edu.ph
    affiliation: 
      - name: UP School of Library and Information Studies
        city: Quezon City
        state: MM
        url: httP://upslis.info
abstract: > 
  In the contemporary era marked by the digital revolution, data science has emerged as a pivotal discipline globally. This study examines the prominence and frequency of data science and its associated terminologies within Philippine newspapers. By analyzing a comprehensive selection of major Philippine dailies over 20 years, we assessed how often and in what context these terms appear. Our findings indicate a steadily increasing trend, reflecting the growing significance and understanding of data science in the country. Notably, the words were most frequently associated with business, technology, and academic news sections. However, there was variability in the depth and accuracy of discussions surrounding these terms. The media's portrayal, in many instances, was foundational, suggesting a burgeoning stage of familiarity with data science concepts among the general populace. This study underscores the role of print media in disseminating and shaping perceptions about emerging technological fields in the Philippines. It offers insights into potential areas for enhanced media literacy and collaboration.
keywords:
  - Data Science
  - Philippines Newspaper
  - Philippine Daily Inquirer
  - Agenda Setting Theory
license: "CC BY"
copyright: 
  holder: Dan Anthony Dorado
  year: 2023
funding: "The author received no specific funding for this work."
format: pdf
toc: false
number-sections: false
highlight-style: github
papersize: letter
link-citations: true
bibliography: https://api.citedrive.com/bib/9ac6b0e9-03b3-4d19-8cce-f0ddb36e10e3/references.bib?x=eyJpZCI6ICI5YWM2YjBlOS0wM2IzLTRkMTktOGNjZS1mMGRkYjM2ZTEwZTMiLCAidXNlciI6ICI2NzA1IiwgInNpZ25hdHVyZSI6ICI5M2U0MzMzNzJhYTk3OWNlOWQzZTg4NjUyNzVmNDkzNjgyNWUzYTg5NDFlYjQ4YzhjZWYwZjkzOWZlZmZhN2Q5In0=/bibliography.bib
csl: sustainability.csl
---

# Introduction

## Background of the study

### Global rise of data science and its influence.

Data science has become increasingly important in decision-making processes across industries. The advancements in data volume and computational capabilities have played a significant role in the growth and application of data science [@Hey2012]. This growth has led to the recognition of data science as a crucial discipline in driving decision-making. Companies have realized the need to hire data scientists, and academic institutions now offer data science programs [@Provost2013]. The application of data science techniques has also expanded to fields such as computer and network security [@Tewari2021]. In sustainable development, data science has become crucial in meeting human development needs while protecting the earth's life support systems [@Cash2003]. By utilizing knowledge systems, scientists, technologists, policymakers, and communities at all levels can work together to find sustainable solutions. Data science has also made a significant impact on global health. Efforts by organizations like Sana (MIT) have played a vital role in promoting data science in global health [@Agha-Mir-Salim2020]. The use of health information technology as a premise for data science in global health has opened up opportunities for improving healthcare outcomes worldwide. In asthma research, data science has helped understand the worldwide prevalence of asthma symptoms. Studies have shown that the global burden of asthma is continuing to rise, with increasing prevalence in Africa, Latin America, and parts of Asia [@Pearce2007]. However, it is essential to note that there has been a lack of new worldwide data on asthma prevalence since 2003 [@Asher2020]. The global macroeconomic impacts of COVID-19 have also been analyzed using data science techniques. Different scenarios have been examined to understand their effects on macroeconomic outcomes and financial markets [@McKibbin2020]. This analysis provides valuable insights for policymakers and economists in navigating the challenges posed by the pandemic. In glaucoma research, data science has been used to analyze the distribution pattern and subject domain knowledge of worldwide glaucoma research [@Ichhpujani2020]. This scientometric review provides a comprehensive understanding of the research landscape in this area. Scholarly production analysis has also benefited from data science methodologies. Studies have compared the performance of different databases, such as Google Scholar, Scopus, and Web of Science, regarding citation analysis and cross-disciplinary coverage @Harzing2015. These analyses contribute to the understanding of the impact and reach of scholarly publications worldwide.

Overall, the global rise of data science has had a transformative influence on various fields. It has enabled researchers, policymakers, and practitioners to gain valuable insights, make informed decisions, and address complex challenges in a data-driven manner. However, it is essential to note that the emphasis on data science education primarily focuses on computer science and statistics, with limited training in ethics and domain-specific knowledge [@Oliver2021]. This highlights the need for a more comprehensive approach to data science education that includes training in ethics and domain-specific context. Additionally, the application of data-driven research methods has extended beyond computer science to disciplines such as social sciences and humanities [@Weichselbraun2021].

### Importance of media in disseminating new terminologies and concepts.

The media is crucial in disseminating new terminologies and concepts to the public. It serves as a platform for introducing and explaining unfamiliar terms and ideas, making them accessible and understandable to a broad audience. A critical aspect of the media's role in disseminating new terminologies and concepts is its ability to reach a large audience. The mass media, including mainstream newspapers, television, and online news outlets, have a broad reach and can effectively communicate new terminologies and concepts to a diverse range of people [@Herman1989]. This widespread dissemination helps to increase awareness and understanding of these new terms and ideas. Furthermore, the media can shape public discourse and influence public opinion. Through news articles, opinion pieces, and other media content, the media can introduce and promote new terminologies and concepts, framing them in a way that resonates with the audience [@Shanahan1988]. This framing can help to shape public perceptions and attitudes towards these new terms and ideas. In addition, the media's role in disseminating new terminologies and concepts extends to specialized fields such as healthcare and medicine. Health journalism, for example, plays a crucial role in sharing health information with the public [@Keshvari2018]. The media can introduce new medical terminologies and concepts, helping to educate the public about important health issues and advancements in medical research.

However, it is essential to note that the media's role in disseminating new terminologies and concepts is not without challenges. One challenge is the potential for the media to misinterpret or misrepresent these new terms and ideas. The media's framing of new terminologies and concepts can sometimes be influenced by various factors, such as political or economic interests [@Herman1989]. This can distort the original meaning or intent of these terms and ideas. Another challenge is the potential for the media to perpetuate stereotypes or biases through the use of new terminologies and concepts. For example, in the context of Islam-related vocabularies, the media's use of specific terms can influence the audience's perception of Islam as a religion of terrorism [@Younes2020]. This highlights the importance of responsible and accurate reporting when introducing and disseminating new terminologies and concepts.

## Objective of the research

Data science and other related terms have emerged as a crucial field in the era of big data and advanced analytics. It encompasses various techniques and methodologies for extracting insights and knowledge from large datasets. The prominence of data science in the Philippines has been a topic of interest, as it plays a significant role in driving innovation, economic growth, and decision-making processes. This research objective aims to assess the frequency and prominence of data science and related terms in Philippine newspapers.

# Literature Review

## Data science: Definition and global trends

Data science is a field dedicated to the principled extraction of knowledge from complex data [@Sanchez-Pinto2018]. It combines principles from statistics, which focuses on learning relationships from data, and computer science, which emphasizes efficient computing algorithms [@Deo2015]. The goal of data science is to extract generalizable knowledge from data [@Song2015]. It is a rapidly growing field becoming increasingly important in various domains, including critical care in medicine [@Sanchez-Pinto2018]. Data science is closely related to other concepts, such as big data and data-driven decision-making [@Provost2013]. It is intricately intertwined with these concepts and plays a crucial role in analyzing and making sense of large volumes of data [@Provost2013]. Data science is often used to rapidly derive knowledge and discover trends and novel research topics from vast literature [@Shen2018].

While data science builds on knowledge from various disciplines, such as computer science, mathematics, and statistics, it is a unique field with challenges and mysteries to unlock [@Wing2020]. It is establishing itself as a profession and has the potential to make significant contributions to society [@Walker2015]. Data science is also characterized by its generic and vaguely defined nature [@Peng2021]. There is no universally accepted definition of data science, and different perspectives exist. Some define data science as the study of the generalizable extraction of knowledge from data [@Song2015], while others emphasize its interdisciplinary nature and its intersection with statistics, computer science, and substantive fields [@Zhang2021].

## Media's role in popularizing technical jargons and scientific terms

The role of media in introducing and normalizing new terminologies and concepts to the public is pivotal in today's rapidly evolving world. As new scientific and technological terms such as 'data science', 'big data', and 'artificial intelligence' emerge, media outlets serve as the primary source for the public's initial exposure to these concepts [@Krosnick2006]. Moreover, the media plays a crucial role in providing context and explanation for these complex terms, making them accessible and understandable to a non-specialist audience. This involves decoding technical jargon and presenting information using metaphors, analogies, and simplifications to convey complex ideas [@Fitzgerald2021].

The influence of media in shaping public understanding extends beyond the introduction of new concepts. It also encompasses the dissemination of knowledge through social media platforms, which have rapidly gained popularity worldwide. The speed of uptake of social media applications highlights their significance as tools for knowledge sharing, further emphasizing the central role of media in the dissemination of information [@Naeem2019]. Additionally, the development of the Internet and social media has expanded the speed and scope of information dissemination, although not all widely disseminated information is accurate, emphasizing the need for critical evaluation of information sources [@Wang2021].

Furthermore, the media's influence on public perception is evident in the context of scientific and technological advancements. The media operates at the interface between science and society, reporting on scientific advances and technological developments in ways that shape public perceptions of new technologies and their applications. This underscores the media's role in framing and agenda setting, particularly in relation to novel technologies, influencing public views and perceptions [@Fitzgerald2021].

## Theoretical Framework

Agenda-setting theory is a well-established and influential theoretical framework in the field of communication research. It focuses on the role of the media in shaping public opinion and influencing the salience of issues in society. According to the theory, the media has the power to determine which issues are important and worthy of public attention, thus setting the agenda for public discourse [@McCombs2006].

One important aspect of agenda-setting theory is the transfer of salience, which refers to the media's ability to not only determine which issues are important but also shape how people think about those issues. This transfer of salience occurs through the media's selection and emphasis of certain issues, which in turn influences the public's perception and understanding of those issues [@McCombs2006]. Furthermore, the media's agenda-setting power extends not only to the salience of issues but also to the salience of their attributes [@Vu2014]. In other words, the media can shape how people think about the characteristics and qualities of specific issues.

Agenda-setting research has evolved over the years, with scholars refining and expanding the scope of the theory. For example, researchers have explored intermedia agenda-setting effects, which examine how different media outlets influence each other in shaping the public agenda. This expansion has led to a more sophisticated understanding of agenda-setting effects and their impact on public opinion [@Lim2006].

Moreover, agenda-setting theory has found applications in various fields, including politics, journalism, and public relations. It has been used to study the influence of the media on political campaigns, the framing of news stories, and the communication of consent [@Caldwell1996; @Meraz2011; @McCombs1997]. The theory has also been examined in the context of online news media, where researchers have analyzed agenda-setting effects among different platforms [@Lim2006].

In recent years, there has been a growing interest in meta-analyses of agenda-setting research, which provide a comprehensive overview of the existing empirical literature. These meta-analyses analyze the evolution of agenda-setting theory in terms of research focus, subject areas, and research methods. By synthesizing and analyzing statistical indicators from a large number of studies, these meta-analyses contribute to a deeper understanding of the current state of agenda-setting research [@Li2022].

# Methodology

## Selection of newspapers

The selection of newspapers for a study focused on data science-related terms is crucial for comprehensive coverage and depth of analysis. In this research, the Philippine Daily Inquirer website has been chosen for several reasons. Firstly, the Philippine Daily Inquirer is one of the most widely read newspapers in the Philippines, ensuring that the analysis is relevant to a broad online audience. Additionally, the extensive archives of the online version of the newspaper are essential for historical data analysis, allowing for an exploration of the evolution of data science terminology over time. The diverse array of articles, including news, opinion pieces, features, and editorials, published on the website is vital for understanding the different contexts in which data science-related terms are used. As a continually updated digital news source, the Philippine Daily Inquirer website offers the most current perspective on the use and understanding of data science terms. Moreover, the newspaper's national scope reflects national interests and discourse, providing a comprehensive overview of how data science is perceived and talked about across the country. The editorial stance and policies of the newspaper provide insight into how data science topics are framed and prioritized, which is an important aspect of media analysis.

## Time frame of the study

The time frame for the study, spanning from 1993 to 2023, is crucial for capturing the evolution of data science in the Philippine media landscape. This extended period allows for the identification of long-term trends and patterns in media coverage related to data science [@Ho2007]. Additionally, the chosen period should align with significant events or developments in the field of data science, such as the introduction of data science courses, government initiatives, or the establishment of data science firms in the Philippines.

The start and end dates of the data collection period should be justified based on the emergence of key events or milestones in the Philippine data science landscape [@Suppli2018]. Furthermore, dividing the time frame into segments, such as monthly or quarterly intervals, allows for a detailed temporal analysis, enabling the examination of changes in reporting frequency or contextual shifts around specific events.

The selected time frame may influence the results and the interpretation of trends in the data, as it allows for the assessment of any immediate effects of significant global or local events on the presence and representation of data science in the press. Considerations for seasonal variations or particular events, such as elections or natural disasters, should also be factored in, as they might affect media coverage and public interest in data science.

If prior data is available, a comparative analysis with previous periods can provide valuable insights into the growth, decline, or cyclical patterns in the coverage of data science-related terms. Anticipating the impact of the time frame on the results is essential, considering how seasonal variations or specific events, such as elections or natural disasters, might influence media coverage and public interest in data science.

## Data Collection Process

This process begins with the careful selection of primary and secondary keywords, such as "**Data Science**", "**Big Data**", "**Analytics**", "**Artificial Intelligence**", along with related terms like "**Robotics**". The search for these keywords is facilitated through the use of search textbook of <https://www.inquirer.net/>. To validate the accuracy and relevance of the automated search results, a manual review process is implemented. This involves random checks to ensure articles are contextually related to data science and its associated fields. Moreover, the entire process is conducted with a strict adherence to ethical and legal considerations, ensuring compliance with copyright laws and respect for privacy and ethical guidelines, especially when handling articles that include interviews or personal data. Through these comprehensive keyword search techniques, the study aims to gather a wide range of data from the Philippine Daily Inquirer, offering detailed insights into the media's portrayal and emphasis on data science and related terms.

# Findings

## Computational Environment and Software

In this study, we employed a robust computational environment to ensure the reliability and reproducibility of our data processing and analysis. Our analysis pipeline was constructed with a focus on using widely-recognized, open-source software to enhance the accessibility and verifiability of our methodologies.

The primary statistical analyses and data processing tasks were conducted using `R` [@R2023], a language and environment specifically designed for statistical computing and graphics. The R environment is renowned for its extensive package ecosystem and its ability to handle a wide range of data types and analytical procedures. For this study, we used `R` version 4.3.0, ensuring that all analyses benefit from the latest improvements and bug fixes.

Complementing `R`, we utilized `RStudio` [@Rstudio2023], an integrated development environment (IDE) that provides a user-friendly interface for `R`. `RStudio` version 2023.06.1+524 was employed, which offers enhanced coding tools, debugging capabilities, and data visualization features. The combination of `R` and `RStudio` provided a versatile and efficient platform for coding, data manipulation, and analysis.

For web scraping and HTML data extraction, the `rvest` package [@rvest2022] in `R` was utilized. This package simplifies the process of reading and manipulating HTML content, making it invaluable for gathering data from web sources. The version 1.0.3 of rvest was specifically used.

Data manipulation and transformation tasks were streamlined using the `tidyverse` collection of `R` packages [@tidyverse2019]. This suite of packages, including `dplyr`, `tidyr`, and `ggplot2`, facilitates efficient data processing and visualization. We specifically employed `tidyverse` version 2.0.0.

The primary operating system used for all data processing tasks was `Windows 11 x64 (build 22621)`. This version of Windows offers enhanced security features, improved performance, and a user-friendly interface, which significantly contributed to the efficiency of our data handling processes. The 64-bit architecture was particularly beneficial for handling large datasets, ensuring that memory-intensive operations were executed smoothly.

For transparency and to facilitate reproducibility of our findings, all scripts and processed data files have been made publicly available. They are hosted on GitHub, a widely recognized platform for version control and code sharing. The repository can be accessed at <https://github.com/dddorado/ds_term_prominence>. This repository includes all the scripts used in the data processing and analysis phases, along with detailed documentation on the usage and functionality of these scripts [@Dorado2023].

## Data Scrapping Process

In this study, we aimed to systematically gather data from <https://www.inquirer.net/>, focusing on identifying and downloading web pages that contain specific keywords of interest. This task was nessesary due to the nature of the website's content presentation. Inquirer.net, like many contemporary news and information websites, leverages modern web technologies to enhance user experience and content delivery. A key aspect of these technologies is the use of `JavaScript` to dynamically load and display content. This approach, commonly employed in web applications developed with frameworks like `Angular`, `React`, or `Vue`, poses a specific challenge for web scraping tools like `rvest`. Once the pages are downloaded, we can now proceed to harvsting its content.

Running the provided code in R will load the rvest and tidyverse packages into your R session.

```{r Load R Packages, eval=TRUE, echo=TRUE, warning=FALSE, results='hide', message=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(tm)
library(tidytext)
```

The code starts by creating a vector `robotics_url` that contains a list of URLs. Each URL points to an HTML page that presumably contains articles related to robotics.

```{r Defining URLs, eval=TRUE, echo=TRUE, results='hide'}
robotics_url <- c('robotics_articles/robotics01.html',
                  'robotics_articles/robotics02.html',
                  'robotics_articles/robotics03.html',
                  'robotics_articles/robotics04.html',
                  'robotics_articles/robotics05.html',
                  'robotics_articles/robotics06.html',
                  'robotics_articles/robotics07.html',
                  'robotics_articles/robotics08.html',
                  'robotics_articles/robotics09.html',
                  'robotics_articles/robotics10.html')
```

An `extractor` function is defined to process each URL. This function uses `read_html` from the `rvest` package to parse the HTML content of the given URL. It then uses a series of `rvest` functions to extract specific data:

- `html_element('div.gsc-expansionArea')`: Selects a division in the HTML document with the class `gsc-expansionArea`.
- `html_nodes('a.gs-title')`: From this division, it finds all hyperlinks (`<a>` tags) with the class `gs-title`, extracting the text from these nodes to get the titles of the articles.
- `html_nodes('div.gs-bidi-start-align.gs-snippet')`: Similarly, it extracts text snippets from divisions with the classes `gs-bidi-start-align` and `gs-snippet`, which likely contain article summaries or content.
- The `unique()` function is applied to the titles to ensure there are no duplicates.
- The function returns a `tibble` (a type of data frame in R) with two columns: `title` and `data`, containing the extracted titles and text snippets, respectively.

```{r Extractor Function, eval=TRUE, echo=TRUE, results='hide'}
extractor <- function(url){
    page <- read_html(url)
    title <- page %>% html_element('div.gsc-expansionArea') %>%
      html_nodes('a.gs-title') %>% 
      html_text() %>% 
      unique()
    data <- page %>% 
      html_element('div.gsc-expansionArea') %>% 
      html_nodes('div.gs-bidi-start-align.gs-snippet') %>% 
      html_text()
    tibble(title = title, data = data)
}
```

The `lapply` function is used to apply the `extractor` function to each URL in the `robotics_url` vector. This results in a list of tibbles, where each tibble contains data scraped from one URL.

```{r Scraping Data, eval=TRUE, echo=TRUE, results='hide'}
robotics_scraped <- lapply(robotics_url, extractor)
```

The scraped data from all URLs are combined into a single tibble using `do.call` with `rbind`, which row-binds the individual tibbles. This creates a consolidated dataset.

```{r Combining Data, eval=TRUE, echo=TRUE, results='hide'}
robotics_combined_data <- do.call(rbind, robotics_scraped)
```

Finally, the code adds a new column named `category` to the combined tibble, assigning the value 'robotics' to each row. This categorization step indicates that all scraped data in this dataset are related to the field of robotics.

```{r Adding Category, eval=TRUE, echo=TRUE, results='hide'}
robotics_combined_data <- robotics_combined_data %>%
    mutate(category = 'robotics')
```

```{r other combined DF, eval=TRUE, echo=FALSE, results='hide'}
ai_url <- c('ai_articles/ai01.html',
                  'ai_articles/ai02.html',
                  'ai_articles/ai03.html',
                  'ai_articles/ai04.html',
                  'ai_articles/ai05.html',
                  'ai_articles/ai06.html',
                  'ai_articles/ai07.html',
                  'ai_articles/ai08.html',
                  'ai_articles/ai09.html',
                  'ai_articles/ai10.html')
analytics_url <- c('analytics_articles/analytics01.html',
                  'analytics_articles/analytics02.html',
                  'analytics_articles/analytics03.html',
                  'analytics_articles/analytics04.html',
                  'analytics_articles/analytics05.html',
                  'analytics_articles/analytics06.html',
                  'analytics_articles/analytics07.html',
                  'analytics_articles/analytics08.html',
                  'analytics_articles/analytics09.html',
                  'analytics_articles/analytics10.html')
big_data_url <- c('big_data_articles/bigdata01.html',
                  'big_data_articles/bigdata02.html',
                  'big_data_articles/bigdata03.html',
                  'big_data_articles/bigdata04.html',
                  'big_data_articles/bigdata05.html',
                  'big_data_articles/bigdata06.html',
                  'big_data_articles/bigdata07.html',
                  'big_data_articles/bigdata08.html',
                  'big_data_articles/bigdata09.html',
                  'big_data_articles/bigdata10.html')
data_science_url <- c('data_science_articles/ds01.html',
                  'data_science_articles/ds02.html',
                  'data_science_articles/ds03.html',
                  'data_science_articles/ds04.html',
                  'data_science_articles/ds05.html',
                  'data_science_articles/ds06.html',
                  'data_science_articles/ds07.html',
                  'data_science_articles/ds08.html',
                  'data_science_articles/ds09.html',
                  'data_science_articles/ds10.html')
ai_scraped <- lapply(ai_url, extractor)
analytics_scraped <- lapply(analytics_url, extractor)
big_data_scraped <- lapply(big_data_url, extractor)
data_science_scraped <- lapply(data_science_url, extractor)
ai_combined_data <- do.call(rbind, ai_scraped)
analytics_combined_data <- do.call(rbind, analytics_scraped)
big_data_combined_data <- do.call(rbind, big_data_scraped)
data_science_combined_data <- do.call(rbind, data_science_scraped)
ai_combined_data <- ai_combined_data %>%
    mutate(category = 'ai')
analytics_combined_data <- analytics_combined_data %>%
    mutate(category = 'analytics')
big_data_combined_data <- big_data_combined_data %>%
    mutate(category = 'big_data')
data_science_combined_data <- data_science_combined_data %>%
    mutate(category = 'data_science')
```

Repeat the process for other downloaded websites. Combine the different datasets (`robotics_combined_data`, `ai_combined_data`, `analytics_combined_data`, `big_data_combined_data`, `data_science_combined_data`) into a single dataset using the `rbind` function. This creates a comprehensive dataset (`compiled_dataset`) containing data from all these categories.

```{r Data Aggregation, eval=TRUE, echo=TRUE, results='hide'}
compiled_dataset <- rbind(robotics_combined_data, 
                          ai_combined_data, 
                          analytics_combined_data, 
                          big_data_combined_data, 
                          data_science_combined_data)
```

It then processes the `data` column to extract dates using `str_extract` with a regex pattern that matches date formats (e.g., "Jan 1, 2020"). These extracted dates are then parsed into a standardized format using `parse_date_time`.

```{r Date Extraction and Parsing, eval=TRUE, echo=TRUE, results='hide'}
compiled_dataset <- compiled_dataset %>%
    mutate(date = str_extract(data, "\\b[A-Z][a-z]{2} \\d{1,2}, \\d{4}\\b"))
compiled_dataset$date <- parse_date_time(compiled_dataset$date, orders = "mdY")
```

## Frequency Analysis

This analysis refers to the process of counting how often each word (or term) appears in the dataset, particularly within the titles of articles across different categories like robotics, AI, analytics, big data, and data science. This kind of analysis helps in understanding which words or terms are most common or prevalent in a given set of texts. Here's the breakdown of how frequency analysis was conducted.

```{r Defining and Combining Stopwords, eval=TRUE, echo=TRUE, results='hide'}
additional_stopwords <- c("ai", 
                          "inquirer", 
                          "artificial", 
                          "intelligence", 
                          "analytics", 
                          "ph", 
                          "data", 
                          "robotics", 
                          "science", 
                          "inquirernet")
all_stopwords <- c(stopwords("en"), additional_stopwords)
```

The script sets up a list of additional stopwords specific to the context (like "ai", "inquirer", etc.) and combines them with the default English stopwords provided by the `tm` package.

A `clean_text` function is then defined to preprocess the text. This function converts text to lowercase, removes punctuation and stopwords, and strips extra whitespace. This function is applied to the `title` column of the dataset.

```{r Text Preprocessing, eval=TRUE, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
clean_text <- function(text) {
    text <- tolower(text) # Convert to lowercase
    text <- removePunctuation(text) # Remove punctuation
    text <- removeWords(text, all_stopwords) # Remove stopwords
    text <- stripWhitespace(text) # Remove extra white spaces
    return(text)
}

compiled_dataset$clean_title <- sapply(compiled_dataset$title, clean_text)
```

We then tokenizes the cleaned titles and calculates term frequencies. It uses `unnest_tokens` to break down the titles into words and then counts the frequency of each word within each category.

```{r Tokenization and Term Frequency Calculation, eval=TRUE, echo=TRUE, results='hide'}
compiled_dataset_clean <- compiled_dataset %>%
    unnest_tokens(word, clean_title) %>%
    count(category, word, sort = TRUE)
```

For each category, we select the top 10 terms based on their frequency using `top_n`.

```{r Selecting Top Terms, eval=TRUE, echo=TRUE, results='hide'}
top_terms <- compiled_dataset_clean %>%
    group_by(category) %>%
    top_n(10, n) %>%
    ungroup()
```

Finally, we use `ggplot2` for data visualization. It creates a bar plot showing the top 10 terms for each category, with terms on the x-axis, frequency on the y-axis, and different colors for each category. The plot uses `facet_wrap` to create separate plots for each category and `coord_flip` for better readability of the terms.

```{r Data Visualization, eval=TRUE, echo=TRUE, fig.height=4}
ggplot(top_terms, aes(x = reorder(word, n), y = n, fill = category)) +
    geom_bar(stat = "identity") +
    facet_wrap(~ category, scales = "free") +
    coord_flip() +
    labs(title = "Top 10 Terms in Titles per Category", x = "Terms", y = "Frequency") +
    theme_minimal()
```

The prominent occurrence of terms related to data science and similar fields in Philippine newspapers suggests several key implications. Firstly, it indicates a growing interest and focus on technology and data science within the country, reflecting the global trend towards data-driven decision-making and artificial intelligence. This prominence could be indicative of heightened public awareness and an educational shift towards these disciplines. Additionally, it might signal the alignment of the Philippines' economic and industrial trends with global advancements in technology.

Furthermore, the frequent coverage of these topics could be reflective of governmental focus and investment in the tech industry, hinting at potential public policy shifts and infrastructure development to support technological growth. The media's role in shaping public perception is also crucial, as this increased focus could influence more individuals to pursue careers in data science and related fields. This trend might also suggest a vibrant business and start-up environment in the tech sector of the Philippines, highlighting growth areas for investment and job creation.

Moreover, the frequent discussions around data science and associated fields might point to societal challenges and opportunities, such as data privacy, ethical AI use, and the need for skilled professionals. Finally, this trend could signify the Philippines' increasing integration into the global tech landscape, indicating its responsiveness to international technological advancements. While the term frequency analysis underscores the prevalence of these topics, it is essential to conduct further qualitative analysis to understand the context and sentiment behind this media coverage fully.

# References
